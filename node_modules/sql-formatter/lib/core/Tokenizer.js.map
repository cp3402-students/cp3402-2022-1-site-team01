{"version":3,"sources":["../../src/core/Tokenizer.ts"],"names":["WHITESPACE_REGEX","NULL_REGEX","Tokenizer","cfg","tokenType","input","getTokenOnFirstMatch","type","regex","REGEX_MAP","specialWordCharsAll","Object","values","specialWordChars","join","TokenType","WORD","regexFactory","createWordRegex","STRING","createStringRegex","stringTypes","RESERVED_KEYWORD","createReservedWordRegex","reservedKeywords","RESERVED_DEPENDENT_CLAUSE","reservedDependentClauses","RESERVED_LOGICAL_OPERATOR","reservedLogicalOperators","RESERVED_COMMAND","reservedCommands","RESERVED_BINARY_COMMAND","reservedBinaryCommands","RESERVED_JOIN_CONDITION","reservedJoinConditions","OPERATOR","createOperatorRegex","operators","BLOCK_START","createParenRegex","blockStart","BLOCK_END","blockEnd","LINE_COMMENT","createLineCommentRegex","lineCommentTypes","BLOCK_COMMENT","NUMBER","PLACEHOLDER","EOF","INDEXED_PLACEHOLDER_REGEX","createPlaceholderRegex","indexedPlaceholderTypes","IDENT_NAMED_PLACEHOLDER_REGEX","namedPlaceholderTypes","STRING_NAMED_PLACEHOLDER_REGEX","createStringPattern","tokens","token","length","whitespaceBefore","getWhitespace","substring","getNextToken","value","push","matches","match","previousToken","matchToken","getPlaceholderToken","getReservedWordToken","placeholderTokenRegexMap","parseKey","v","slice","getEscapedPlaceholderKey","key","quoteChar","reduce","acc","undefined","replace","RegExp","reservedTokenList","matchedToken"],"mappings":";;;;;;;;;AAAA;;AACA;;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAA4C;AAErC,IAAMA,gBAAgB,GAAG,yEAAzB;;AACP,IAAMC,UAAU,GAAG,MAAnB,C,CAA2B;;AAE3B;;AAkBA;IACqBC,S;AAOnB;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACE,qBAAYC,GAAZ,EAAmC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;;AAAA;;AAAA;;AAAA;;AAAA,wCAiGjC,UAACC,SAAD;AAAA,aACA,UAACC,KAAD;AAAA,eACE,KAAI,CAACC,oBAAL,CAA0B;AACxBD,UAAAA,KAAK,EAALA,KADwB;AAExBE,UAAAA,IAAI,EAAEH,SAFkB;AAGxBI,UAAAA,KAAK,EAAE,KAAI,CAACC,SAAL,CAAeL,SAAf;AAHiB,SAA1B,CADF;AAAA,OADA;AAAA,KAjGiC;;AACjC,QAAMM,mBAAmB,GAAGC,MAAM,CAACC,MAAP,0BAAcT,GAAG,CAACU,gBAAlB,yEAAsC,EAAtC,EAA0CC,IAA1C,CAA+C,EAA/C,CAA5B;AACA,SAAKL,SAAL,2DACGM,iBAAUC,IADb,EACoBC,YAAY,CAACC,eAAb,CAA6Bf,GAAG,CAACU,gBAAjC,CADpB,oCAEGE,iBAAUI,MAFb,EAEsBF,YAAY,CAACG,iBAAb,CAA+BjB,GAAG,CAACkB,WAAnC,CAFtB,oCAGGN,iBAAUO,gBAHb,EAGgCL,YAAY,CAACM,uBAAb,CAC5BpB,GAAG,CAACqB,gBADwB,EAE5Bd,mBAF4B,CAHhC,oCAOGK,iBAAUU,yBAPb,EAOyCR,YAAY,CAACM,uBAAb,0BACrCpB,GAAG,CAACuB,wBADiC,yEACL,EADK,EAErChB,mBAFqC,CAPzC,oCAWGK,iBAAUY,yBAXb,EAWyCV,YAAY,CAACM,uBAAb,CACrCpB,GAAG,CAACyB,wBADiC,EAErClB,mBAFqC,CAXzC,oCAeGK,iBAAUc,gBAfb,EAegCZ,YAAY,CAACM,uBAAb,CAC5BpB,GAAG,CAAC2B,gBADwB,EAE5BpB,mBAF4B,CAfhC,oCAmBGK,iBAAUgB,uBAnBb,EAmBuCd,YAAY,CAACM,uBAAb,CACnCpB,GAAG,CAAC6B,sBAD+B,EAEnCtB,mBAFmC,CAnBvC,oCAuBGK,iBAAUkB,uBAvBb,EAuBuChB,YAAY,CAACM,uBAAb,CACnCpB,GAAG,CAAC+B,sBAD+B,EAEnCxB,mBAFmC,CAvBvC,oCA2BGK,iBAAUoB,QA3Bb,EA2BwBlB,YAAY,CAACmB,mBAAb,CAAiC,uBAAjC,GACpB,IADoB,EAEpB,IAFoB,EAGpB,IAHoB,EAIpB,IAJoB,8CAKhBjC,GAAG,CAACkC,SALY,2DAKC,EALD,GA3BxB,oCAkCGtB,iBAAUuB,WAlCb,EAkC2BrB,YAAY,CAACsB,gBAAb,CAA8BpC,GAAG,CAACqC,UAAlC,CAlC3B,oCAmCGzB,iBAAU0B,SAnCb,EAmCyBxB,YAAY,CAACsB,gBAAb,CAA8BpC,GAAG,CAACuC,QAAlC,CAnCzB,oCAoCG3B,iBAAU4B,YApCb,EAoC4B1B,YAAY,CAAC2B,sBAAb,CAAoCzC,GAAG,CAAC0C,gBAAxC,CApC5B,oCAqCG9B,iBAAU+B,aArCb,EAqC6B,qCArC7B,oCAsCG/B,iBAAUgC,MAtCb,EAuCI,yJAvCJ,oCAwCGhC,iBAAUiC,WAxCb,EAwC2B/C,UAxC3B,oCAyCGc,iBAAUkC,GAzCb,EAyCmBhD,UAzCnB;AA4CA,SAAKiD,yBAAL,GAAiCjC,YAAY,CAACkC,sBAAb,0BAC/BhD,GAAG,CAACiD,uBAD2B,yEACA,EADA,EAE/B,QAF+B,CAAjC;AAIA,SAAKC,6BAAL,GAAqCpC,YAAY,CAACkC,sBAAb,CACnChD,GAAG,CAACmD,qBAD+B,EAEnC,iBAFmC,CAArC;AAIA,SAAKC,8BAAL,GAAsCtC,YAAY,CAACkC,sBAAb,CACpChD,GAAG,CAACmD,qBADgC,EAEpCrC,YAAY,CAACuC,mBAAb,CAAiCrD,GAAG,CAACkB,WAArC,CAFoC,CAAtC;AAID;AAED;AACF;AACA;AACA;AACA;AACA;AACA;;;;;WACE,kBAAShB,KAAT,EAAiC;AAC/B,UAAMoD,MAAe,GAAG,EAAxB;AACA,UAAIC,KAAJ,CAF+B,CAI/B;;AACA,aAAOrD,KAAK,CAACsD,MAAb,EAAqB;AACnB;AACA,YAAMC,gBAAgB,GAAG,KAAKC,aAAL,CAAmBxD,KAAnB,CAAzB;AACAA,QAAAA,KAAK,GAAGA,KAAK,CAACyD,SAAN,CAAgBF,gBAAgB,CAACD,MAAjC,CAAR;;AAEA,YAAItD,KAAK,CAACsD,MAAV,EAAkB;AAChB;AACAD,UAAAA,KAAK,GAAG,KAAKK,YAAL,CAAkB1D,KAAlB,EAAyBqD,KAAzB,CAAR,CAFgB,CAGhB;;AACArD,UAAAA,KAAK,GAAGA,KAAK,CAACyD,SAAN,CAAgBJ,KAAK,CAACM,KAAN,CAAYL,MAA5B,CAAR;AAEAF,UAAAA,MAAM,CAACQ,IAAP,iCAAiBP,KAAjB;AAAwBE,YAAAA,gBAAgB,EAAhBA;AAAxB;AACD;AACF;;AACD,aAAOH,MAAP;AACD;AAED;;;;WACA,uBAAcpD,KAAd,EAAqC;AACnC,UAAM6D,OAAO,GAAG7D,KAAK,CAAC8D,KAAN,CAAYnE,gBAAZ,CAAhB;AACA,aAAOkE,OAAO,GAAGA,OAAO,CAAC,CAAD,CAAV,GAAgB,EAA9B;AACD;AAED;;;;;AAUA;AACA,0BAAa7D,KAAb,EAA4B+D,aAA5B,EAAmD;AACjD,aAAQ,KAAKC,UAAL,CAAgBtD,iBAAU4B,YAA1B,EAAwCtC,KAAxC,KACN,KAAKgE,UAAL,CAAgBtD,iBAAU+B,aAA1B,EAAyCzC,KAAzC,CADM,IAEN,KAAKgE,UAAL,CAAgBtD,iBAAUI,MAA1B,EAAkCd,KAAlC,CAFM,IAGN,KAAKgE,UAAL,CAAgBtD,iBAAUuB,WAA1B,EAAuCjC,KAAvC,CAHM,IAIN,KAAKgE,UAAL,CAAgBtD,iBAAU0B,SAA1B,EAAqCpC,KAArC,CAJM,IAKN,KAAKiE,mBAAL,CAAyBjE,KAAzB,CALM,IAMN,KAAKgE,UAAL,CAAgBtD,iBAAUgC,MAA1B,EAAkC1C,KAAlC,CANM,IAON,KAAKkE,oBAAL,CAA0BlE,KAA1B,EAAiC+D,aAAjC,CAPM,IAQN,KAAKC,UAAL,CAAgBtD,iBAAUC,IAA1B,EAAgCX,KAAhC,CARM,IASN,KAAKgE,UAAL,CAAgBtD,iBAAUoB,QAA1B,EAAoC9B,KAApC,CATF;AAUD;AAED;AACF;AACA;AACA;;;;WACE,6BAAoBA,KAApB,EAAsD;AAAA;AAAA;AAAA;AAAA;;AACpD,UAAMmE,wBAA8E,GAAG,CACrF;AACA;AACEhE,QAAAA,KAAK,2BAAE,KAAK6C,6BAAP,yEAAwCpD,UAD/C;AAEEwE,QAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,iBAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAFb,OAFqF,EAMrF;AACA;AACEnE,QAAAA,KAAK,2BAAE,KAAK+C,8BAAP,yEAAyCtD,UADhD;AAEEwE,QAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,iBACT,MAAI,CAACE,wBAAL,CAA8B;AAAEC,YAAAA,GAAG,EAAEH,CAAC,CAACC,KAAF,CAAQ,CAAR,EAAW,CAAC,CAAZ,CAAP;AAAuBG,YAAAA,SAAS,EAAEJ,CAAC,CAACC,KAAF,CAAQ,CAAC,CAAT;AAAlC,WAA9B,CADS;AAAA;AAFb,OAPqF,EAYrF;AACA;AACEnE,QAAAA,KAAK,2BAAE,KAAK0C,yBAAP,yEAAoCjD,UAD3C;AAEEwE,QAAAA,QAAQ,EAAE,kBAAAC,CAAC;AAAA,iBAAIA,CAAC,CAACC,KAAF,CAAQ,CAAR,CAAJ;AAAA;AAFb,OAbqF,CAAvF;AAmBA,aAAOH,wBAAwB,CAACO,MAAzB,CAAgC,UAACC,GAAD,QAA8B;AAAA,YAAtBxE,KAAsB,QAAtBA,KAAsB;AAAA,YAAfiE,QAAe,QAAfA,QAAe;;AACnE,YAAMf,KAAK,GAAG,MAAI,CAACpD,oBAAL,CAA0B;AAAED,UAAAA,KAAK,EAALA,KAAF;AAASG,UAAAA,KAAK,EAALA,KAAT;AAAgBD,UAAAA,IAAI,EAAEQ,iBAAUiC;AAAhC,SAA1B,CAAd;;AACA,eAAOU,KAAK,mCAAQA,KAAR;AAAemB,UAAAA,GAAG,EAAEJ,QAAQ,CAACf,KAAK,CAACM,KAAP;AAA5B,aAA8CgB,GAA1D;AACD,OAHM,EAGJC,SAHI,CAAP;AAID;;;WAED,yCAAyF;AAAA,UAA9DJ,GAA8D,SAA9DA,GAA8D;AAAA,UAAzDC,SAAyD,SAAzDA,SAAyD;AACvF,aAAOD,GAAG,CAACK,OAAJ,CAAY,IAAIC,MAAJ,CAAW,yBAAa,OAAOL,SAApB,CAAX,EAA2C,IAA3C,CAAZ,EAA8DA,SAA9D,CAAP;AACD;AAED;AACF;AACA;AACA;;;;WACE,8BAAqBzE,KAArB,EAAoC+D,aAApC,EAA8E;AAAA;;AAC5E;AACA;AACA,UAAI,CAAAA,aAAa,SAAb,IAAAA,aAAa,WAAb,YAAAA,aAAa,CAAEJ,KAAf,MAAyB,GAA7B,EAAkC;AAChC,eAAOiB,SAAP;AACD,OAL2E,CAO5E;;;AACA,UAAMG,iBAAiB,GAAG,CACxBrE,iBAAUc,gBADc,EAExBd,iBAAUgB,uBAFc,EAGxBhB,iBAAUU,yBAHc,EAIxBV,iBAAUY,yBAJc,EAKxBZ,iBAAUkB,uBALc,EAMxBlB,iBAAUO,gBANc,CAA1B;AASA,aAAO8D,iBAAiB,CAACL,MAAlB,CACL,UAACM,YAAD,EAAejF,SAAf;AAAA,eAA6BiF,YAAY,IAAI,MAAI,CAAChB,UAAL,CAAgBjE,SAAhB,EAA2BC,KAA3B,CAA7C;AAAA,OADK,EAEL4E,SAFK,CAAP;AAID;AAED;AACF;AACA;AACA;AACA;AACA;AACA;;;;WACE,qCAQsB;AAAA,UAPpB5E,KAOoB,SAPpBA,KAOoB;AAAA,UANpBE,IAMoB,SANpBA,IAMoB;AAAA,UALpBC,KAKoB,SALpBA,KAKoB;AACpB,UAAM0D,OAAO,GAAG7D,KAAK,CAAC8D,KAAN,CAAY3D,KAAZ,CAAhB;AACA,aAAO0D,OAAO,GAAI;AAAE3D,QAAAA,IAAI,EAAJA,IAAF;AAAQyD,QAAAA,KAAK,EAAEE,OAAO,CAAC,CAAD;AAAtB,OAAJ,GAA4Ce,SAA1D;AACD","sourcesContent":["import * as regexFactory from './regexFactory';\nimport { escapeRegExp } from '../utils';\nimport { Token, TokenType } from './token'; // convert to partial type import in TS 4.5\n\nexport const WHITESPACE_REGEX = /^(\\s+)/u;\nconst NULL_REGEX = /(?!)/; // zero-width negative lookahead, matches nothing\n\n/** Struct that defines how a SQL language can be broken into tokens */\ninterface TokenizerOptions {\n  reservedKeywords: string[];\n  reservedCommands: string[];\n  reservedLogicalOperators: string[];\n  reservedDependentClauses: string[];\n  reservedBinaryCommands: string[];\n  reservedJoinConditions: string[];\n  stringTypes: regexFactory.StringPatternType[];\n  blockStart: string[];\n  blockEnd: string[];\n  indexedPlaceholderTypes?: string[];\n  namedPlaceholderTypes: string[];\n  lineCommentTypes: string[];\n  specialWordChars?: { prefix?: string; any?: string; suffix?: string };\n  operators?: string[];\n}\n\n/** Converts SQL language string into a token stream */\nexport default class Tokenizer {\n  REGEX_MAP: { [tokenType in TokenType]: RegExp };\n\n  INDEXED_PLACEHOLDER_REGEX?: RegExp;\n  IDENT_NAMED_PLACEHOLDER_REGEX?: RegExp;\n  STRING_NAMED_PLACEHOLDER_REGEX?: RegExp;\n\n  /**\n   * @param {TokenizerOptions} cfg\n   *  @param {string[]} cfg.reservedKeywords - Reserved words in SQL\n   *  @param {string[]} cfg.reservedDependentClauses - Words that following a specific Statement and must have data attached\n   *  @param {string[]} cfg.reservedLogicalOperators - Words that are set to newline\n   *  @param {string[]} cfg.reservedCommands - Words that are set to new line separately\n   *  @param {string[]} cfg.reservedBinaryCommands - Words that are top level but have no indentation\n   *  @param {string[]} cfg.reservedJoinConditions - ON and USING\n   *  @param {string[]} cfg.stringTypes - string types to enable - \"\", '', ``, [], N''\n   *  @param {string[]} cfg.blockStart - Opening parentheses to enable, like (, [\n   *  @param {string[]} cfg.blockEnd - Closing parentheses to enable, like ), ]\n   *  @param {string[]} cfg.indexedPlaceholderTypes - Prefixes for indexed placeholders, like ?\n   *  @param {string[]} cfg.namedPlaceholderTypes - Prefixes for named placeholders, like @ and :\n   *  @param {string[]} cfg.lineCommentTypes - Line comments to enable, like # and --\n   *  @param {string[]} cfg.specialWordChars - Special chars that can be found inside of words, like @ and #\n   *  @param {string[]} cfg.operators - Additional operators to recognize\n   */\n  constructor(cfg: TokenizerOptions) {\n    const specialWordCharsAll = Object.values(cfg.specialWordChars ?? {}).join('');\n    this.REGEX_MAP = {\n      [TokenType.WORD]: regexFactory.createWordRegex(cfg.specialWordChars),\n      [TokenType.STRING]: regexFactory.createStringRegex(cfg.stringTypes),\n      [TokenType.RESERVED_KEYWORD]: regexFactory.createReservedWordRegex(\n        cfg.reservedKeywords,\n        specialWordCharsAll\n      ),\n      [TokenType.RESERVED_DEPENDENT_CLAUSE]: regexFactory.createReservedWordRegex(\n        cfg.reservedDependentClauses ?? [],\n        specialWordCharsAll\n      ),\n      [TokenType.RESERVED_LOGICAL_OPERATOR]: regexFactory.createReservedWordRegex(\n        cfg.reservedLogicalOperators,\n        specialWordCharsAll\n      ),\n      [TokenType.RESERVED_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedCommands,\n        specialWordCharsAll\n      ),\n      [TokenType.RESERVED_BINARY_COMMAND]: regexFactory.createReservedWordRegex(\n        cfg.reservedBinaryCommands,\n        specialWordCharsAll\n      ),\n      [TokenType.RESERVED_JOIN_CONDITION]: regexFactory.createReservedWordRegex(\n        cfg.reservedJoinConditions,\n        specialWordCharsAll\n      ),\n      [TokenType.OPERATOR]: regexFactory.createOperatorRegex('+-/*%&|^><=.,;[]{}`:$', [\n        '<>',\n        '<=',\n        '>=',\n        '!=',\n        ...(cfg.operators ?? []),\n      ]),\n      [TokenType.BLOCK_START]: regexFactory.createParenRegex(cfg.blockStart),\n      [TokenType.BLOCK_END]: regexFactory.createParenRegex(cfg.blockEnd),\n      [TokenType.LINE_COMMENT]: regexFactory.createLineCommentRegex(cfg.lineCommentTypes),\n      [TokenType.BLOCK_COMMENT]: /^(\\/\\*[^]*?(?:\\*\\/|$))/u,\n      [TokenType.NUMBER]:\n        /^(0x[0-9a-fA-F]+|0b[01]+|(-\\s*)?[0-9]+(\\.[0-9]*)?([eE][-+]?[0-9]+(\\.[0-9]+)?)?)/u,\n      [TokenType.PLACEHOLDER]: NULL_REGEX, // matches nothing\n      [TokenType.EOF]: NULL_REGEX, // matches nothing\n    };\n\n    this.INDEXED_PLACEHOLDER_REGEX = regexFactory.createPlaceholderRegex(\n      cfg.indexedPlaceholderTypes ?? [],\n      '[0-9]*'\n    );\n    this.IDENT_NAMED_PLACEHOLDER_REGEX = regexFactory.createPlaceholderRegex(\n      cfg.namedPlaceholderTypes,\n      '[a-zA-Z0-9._$]+'\n    );\n    this.STRING_NAMED_PLACEHOLDER_REGEX = regexFactory.createPlaceholderRegex(\n      cfg.namedPlaceholderTypes,\n      regexFactory.createStringPattern(cfg.stringTypes)\n    );\n  }\n\n  /**\n   * Takes a SQL string and breaks it into tokens.\n   * Each token is an object with type and value.\n   *\n   * @param {string} input - The SQL string\n   * @returns {Token[]} output token stream\n   */\n  tokenize(input: string): Token[] {\n    const tokens: Token[] = [];\n    let token: Token | undefined;\n\n    // Keep processing the string until it is empty\n    while (input.length) {\n      // grab any preceding whitespace\n      const whitespaceBefore = this.getWhitespace(input);\n      input = input.substring(whitespaceBefore.length);\n\n      if (input.length) {\n        // Get the next token and the token type\n        token = this.getNextToken(input, token);\n        // Advance the string\n        input = input.substring(token.value.length);\n\n        tokens.push({ ...token, whitespaceBefore });\n      }\n    }\n    return tokens;\n  }\n\n  /** Matches preceding whitespace if present */\n  getWhitespace(input: string): string {\n    const matches = input.match(WHITESPACE_REGEX);\n    return matches ? matches[1] : '';\n  }\n\n  /** Curried function of `getTokenOnFirstMatch` that allows token type to be passed first */\n  matchToken =\n    (tokenType: TokenType) =>\n    (input: string): Token | undefined =>\n      this.getTokenOnFirstMatch({\n        input,\n        type: tokenType,\n        regex: this.REGEX_MAP[tokenType],\n      });\n\n  /** Attempts to match next token from input string, tests RegExp patterns in decreasing priority */\n  getNextToken(input: string, previousToken?: Token) {\n    return (this.matchToken(TokenType.LINE_COMMENT)(input) ||\n      this.matchToken(TokenType.BLOCK_COMMENT)(input) ||\n      this.matchToken(TokenType.STRING)(input) ||\n      this.matchToken(TokenType.BLOCK_START)(input) ||\n      this.matchToken(TokenType.BLOCK_END)(input) ||\n      this.getPlaceholderToken(input) ||\n      this.matchToken(TokenType.NUMBER)(input) ||\n      this.getReservedWordToken(input, previousToken) ||\n      this.matchToken(TokenType.WORD)(input) ||\n      this.matchToken(TokenType.OPERATOR)(input)) as Token;\n  }\n\n  /**\n   * Attempts to match a placeholder token pattern\n   * @return {Token | undefined} - The placeholder token if found, otherwise undefined\n   */\n  getPlaceholderToken(input: string): Token | undefined {\n    const placeholderTokenRegexMap: { regex: RegExp; parseKey: (s: string) => string }[] = [\n      // pattern for placeholder with identifier name\n      {\n        regex: this.IDENT_NAMED_PLACEHOLDER_REGEX ?? NULL_REGEX,\n        parseKey: v => v.slice(1),\n      },\n      // pattern for placeholder with string name\n      {\n        regex: this.STRING_NAMED_PLACEHOLDER_REGEX ?? NULL_REGEX,\n        parseKey: v =>\n          this.getEscapedPlaceholderKey({ key: v.slice(2, -1), quoteChar: v.slice(-1) }),\n      },\n      // pattern for placeholder with numeric index\n      {\n        regex: this.INDEXED_PLACEHOLDER_REGEX ?? NULL_REGEX,\n        parseKey: v => v.slice(1),\n      },\n    ];\n\n    return placeholderTokenRegexMap.reduce((acc, { regex, parseKey }) => {\n      const token = this.getTokenOnFirstMatch({ input, regex, type: TokenType.PLACEHOLDER });\n      return token ? { ...token, key: parseKey(token.value) } : acc;\n    }, undefined as Token | undefined);\n  }\n\n  getEscapedPlaceholderKey({ key, quoteChar }: { key: string; quoteChar: string }): string {\n    return key.replace(new RegExp(escapeRegExp('\\\\' + quoteChar), 'gu'), quoteChar);\n  }\n\n  /**\n   * Attempts to match a Reserved word token pattern, avoiding edge cases of Reserved words within string tokens\n   * @return {Token | undefined} - The Reserved word token if found, otherwise undefined\n   */\n  getReservedWordToken(input: string, previousToken?: Token): Token | undefined {\n    // A reserved word cannot be preceded by a '.'\n    // this makes it so in \"mytable.from\", \"from\" is not considered a reserved word\n    if (previousToken?.value === '.') {\n      return undefined;\n    }\n\n    // prioritised list of Reserved token types\n    const reservedTokenList = [\n      TokenType.RESERVED_COMMAND,\n      TokenType.RESERVED_BINARY_COMMAND,\n      TokenType.RESERVED_DEPENDENT_CLAUSE,\n      TokenType.RESERVED_LOGICAL_OPERATOR,\n      TokenType.RESERVED_JOIN_CONDITION,\n      TokenType.RESERVED_KEYWORD,\n    ];\n\n    return reservedTokenList.reduce(\n      (matchedToken, tokenType) => matchedToken || this.matchToken(tokenType)(input),\n      undefined as Token | undefined\n    );\n  }\n\n  /**\n   * Attempts to match RegExp from head of input, returning undefined if not found\n   * @param {string} _.input - The string to match\n   * @param {TokenType} _.type - The type of token to match against\n   * @param {RegExp} _.regex - The regex to match\n   * @return {Token | undefined} - The matched token if found, otherwise undefined\n   */\n  getTokenOnFirstMatch({\n    input,\n    type,\n    regex,\n  }: {\n    input: string;\n    type: TokenType;\n    regex: RegExp;\n  }): Token | undefined {\n    const matches = input.match(regex);\n    return matches ? ({ type, value: matches[1] } as Token) : undefined;\n  }\n}\n"],"file":"Tokenizer.js"}